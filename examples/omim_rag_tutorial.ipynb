{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OMIM-RAG Score Collection Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we demonstrate the pipeline of getting penalty factors for a pre-specified list of genes, with their names supplied as a .pkl or a .txt file. <br> \n",
    "Specifically, the process consists of three steps: <br>\n",
    "(1). Scraping down information from OMIM with OMIM API into JSON files. <br>\n",
    "(2). Preprocessing the scraped OMIM JSON files and Populating a Chroma-based vectorstore using the OMIM knowledge base. <br>\n",
    "(3). Collecting penalty factors with a specified user prompt and an LLM model. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from omim_scrape.parse_omim import *\n",
    "from src.llm_lasso.utils.chunking import chunk_by_gene\n",
    "from omim_scrape.process_mim_number import *\n",
    "from src.llm_lasso.task_specific_lasso.llm_lasso import *\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.schema import Document\n",
    "import constants\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1). Scraping OMIM entries for pre-specified list of gene names. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Update _my_constants.py file with your API keys, including OMIM API and OpenRouter and/or OpenAI APIs.\n",
    "# Step 2: Test that the OMIM API key is working. \n",
    "test_omim_api_access()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Fetch MIM numbers for a list of genes\n",
    "file_path = 'example_data/example_genenames.txt'\n",
    "save_mim_path = 'example_data/example_mim_nums.pkl'\n",
    "mim_dict = get_specified_mim(file_path, save_mim_path)\n",
    "print(mim_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Save scraped output from OMIM database using the fetched MIM numbers\n",
    "save_json_path = 'example_data/omim_context.json'\n",
    "process_mim_numbers_to_json(save_mim_path, save_json_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2). Preprocessing and preparing an OMIM knowledge base for the specified list of genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: preprocess the raw JSON files by chunking\n",
    "chunked_json_path = 'example_data/omim_context_chunked.json'\n",
    "chunk_by_gene(save_json_path, chunked_json_path, chunk_size=1000, chunk_overlap=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Populating the vector-store using the preprocessed OMIM JSON files.\n",
    "\n",
    "# (i). Load chunked data from both sources\n",
    "print(\"Loading chunked JSON data from both sources...\")\n",
    "documents = []\n",
    "\n",
    "# Load scraped OMIM data\n",
    "with open(chunked_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        entry = json.loads(line)\n",
    "        documents.append(entry)\n",
    "\n",
    "print(f\"Loaded {len(documents)} total chunks from omim database.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (ii). Initialize embeddings\n",
    "os.environ[\"OPENAI_API_KEY\"] = constants.OPENAI_API\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# (iii). Create or load the OMIM-based vector store\n",
    "PERSIST = True # Enable persistence to save the database to disk; set False otherwise.\n",
    "persist_directory = \"example_data/omim_vectorstore\"  # Directory to save the vectorstore\n",
    "if PERSIST and os.path.exists(persist_directory):\n",
    "    print(\"Reusing existing database...\")\n",
    "    vectorstore = Chroma(persist_directory=persist_directory, embedding_function=embeddings)\n",
    "else:\n",
    "    print(\"Creating a new database...\")\n",
    "    # Wrap each entry into a Document object\n",
    "    documents_wrapped = [\n",
    "        Document(page_content=doc['content'], metadata=doc['metadata']) for doc in documents\n",
    "    ]\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=documents_wrapped,  # Use the wrapped documents\n",
    "        embedding=embeddings,\n",
    "        persist_directory=persist_directory\n",
    "    )\n",
    "    if PERSIST:\n",
    "        vectorstore.persist()  # Save the combined database to disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3). Collect penalty factors for the list of genes using a RAG-enhanced LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional integration with the langsmith API to trace retrieved documents.\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = constants.LANGCHAIN_API # YOUR API HERE\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"YOUR PROJECT NAME\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define your user prompt in \"example_data/user_prompt.txt\"\n",
    "# Step 2: Edit constants.py and set OMIM_PERSIST_DIRECTORY = \"examples/example_data/omim_vectorstore\"\n",
    "# Step 3: Get LLM scores using the following command line with omim_rag enabled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Navigate to the outer directory to use command line:\n",
    "```\n",
    "cd ..\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With RAG:\n",
    " ```\n",
    "$ python scripts/llm_lasso_scores.py \\\n",
    "        --prompt-filename \"examples/example_data/user_prompt.txt\" \\\n",
    "        --feature_names_path \"examples/example_data/example_genenames.txt\" \\\n",
    "        --category \"Follicular Lymphoma (FL) and Diffuse Large B-Cell Lymphoma (DLBCL)\" \\\n",
    "        --wipe \\\n",
    "        --omim_rag \\\n",
    "        --save_dir \"examples/example_data\" \\\n",
    "        --n-trials 1 \\\n",
    "        --model-type gpt-4o \\\n",
    "        --temp 0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use additional features for penalty collection, see documentations at from src/llm_lasso/llm_penalty/penalty_collection.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-lasso",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
