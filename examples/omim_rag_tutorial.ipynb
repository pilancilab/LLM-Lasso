{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OMIM-RAG Score Collection Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we demonstrate the pipeline of getting penalty factors for a pre-specified list of genes, with their names supplied as a .pkl or a .txt file. <br> \n",
    "\n",
    "Specifically, the process consists of three steps: <br>\n",
    "(1). Scraping down information from OMIM with OMIM API into JSON files. <br>\n",
    "(2). Preprocessing the scraped OMIM JSON files and populating a Chroma-based vectorstore using the OMIM knowledge base. <br>\n",
    "(3). Collecting penalty factors with a specified user prompt and an LLM model. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from omim_scrape.parse_omim import *\n",
    "from src.llm_lasso.utils.chunking import chunk_by_gene\n",
    "from omim_scrape.process_mim_number import *\n",
    "from src.llm_lasso.task_specific_lasso.llm_lasso import *\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.schema import Document\n",
    "import constants\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1). Scraping OMIM entries for pre-specified list of gene names. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Update _my_constants.py file with your API keys, including OMIM API and OpenRouter and/or OpenAI APIs.\n",
    "# Step 2: Test that the OMIM API key is working. \n",
    "test_omim_api_access()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Fetch MIM numbers for a list of genes\n",
    "file_path = 'example_data/example_genenames.txt'\n",
    "save_mim_path = '../omim_scrape/example/example_mim_nums.pkl'\n",
    "mim_dict = get_specified_mim(file_path, constants.OMIM_KEYS[0], save_mim_path)\n",
    "print(mim_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Save scraped output from OMIM database using the fetched MIM numbers\n",
    "save_json_path = '../omim_scrape/example/omim_context.json'\n",
    "process_mim_numbers_to_json(save_mim_path, save_json_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2). Preprocessing and preparing an OMIM knowledge base for the specified list of genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: preprocess the raw JSON files by chunking\n",
    "chunked_json_path = '../omim_scrape/example/omim_context_chunked.json'\n",
    "chunk_by_gene(save_json_path, chunked_json_path, chunk_size=1000, chunk_overlap=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Populating the vector-store using the preprocessed OMIM JSON files.\n",
    "\n",
    "# (i). Load chunked data from both sources\n",
    "print(\"Loading chunked JSON data from both sources...\")\n",
    "documents = []\n",
    "\n",
    "# Load scraped OMIM data\n",
    "with open(chunked_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        entry = json.loads(line)\n",
    "        documents.append(entry)\n",
    "\n",
    "print(f\"Loaded {len(documents)} total chunks from omim database.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (ii). Initialize embeddings\n",
    "os.environ[\"OPENAI_API_KEY\"] = constants.OPENAI_API\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# (iii). Create or load the OMIM-based vector store\n",
    "PERSIST = True # Enable persistence to save the database to disk; set False otherwise.\n",
    "persist_directory = \"../omim_scrape/example/omim_vectorstore\"  # Directory to save the vectorstore\n",
    "if PERSIST and os.path.exists(persist_directory):\n",
    "    print(\"Reusing existing database...\")\n",
    "    vectorstore = Chroma(persist_directory=persist_directory, embedding_function=embeddings)\n",
    "else:\n",
    "    print(\"Creating a new database...\")\n",
    "    # Wrap each entry into a Document object\n",
    "    documents_wrapped = [\n",
    "        Document(page_content=doc['content'], metadata=doc['metadata']) for doc in documents\n",
    "    ]\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=documents_wrapped,  # Use the wrapped documents\n",
    "        embedding=embeddings,\n",
    "        persist_directory=persist_directory\n",
    "    )\n",
    "    if PERSIST:\n",
    "        vectorstore.persist()  # Save the combined database to disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3). Collect penalty factors for the list of genes using a RAG-enhanced LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional integration with the langsmith API to trace retrieved documents.\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = constants.LANGCHAIN_API # YOUR API HERE\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"YOUR PROJECT NAME\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instructions\n",
    "**Step 1**: Define your user prompt in `\"example_data/user_prompt.txt\"`\n",
    "\n",
    "**Step 2**: Edit `_my_constants.py` and set `OMIM_PERSIST_DIRECTORY = \"omim_scrape/example/example_data/omim_vectorstore\"`\n",
    "\n",
    "**Step 3**: Get LLM scores using the following command line with omim_rag enabled:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Navigate to the outer directory to use command line:\n",
    "```\n",
    "cd ..\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With RAG:\n",
    " ```\n",
    "$ python scripts/llm_lasso_scores.py \\\n",
    "        --prompt-filename \"examples/example_data/user_prompt.txt\" \\\n",
    "        --feature_names_path \"examples/example_data/example_genenames.txt\" \\\n",
    "        --category \"Follicular Lymphoma (FL) and Diffuse Large B-Cell Lymphoma (DLBCL)\" \\\n",
    "        --wipe \\\n",
    "        --omim_rag \\\n",
    "        --save_dir \"examples/example_data\" \\\n",
    "        --n-trials 1 \\\n",
    "        --model-type gpt-4o \\\n",
    "        --temp 0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use additional features for penalty collection, see documentations at from `src/llm_lasso/llm_penalty/penalty_collection.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * Scraping the entire OMIM Database\n",
    "\n",
    "Regarding the process of scraping the full OMIM database to build the RAG knowledge base used in the paper, users must first download the file `mim2gene.txt` from OMIM using their registered API key. For this tutorial, please save it to directory `example_data/`.\n",
    "\n",
    "`mim2gene.txt` contains a table that describes the entire contents of the OMIM database. Not all of the entries in `min2gene.txt`, however, are genes, so to obtain a list of valid MIM numbers for genes, we run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_all_valid_mim_numbers(file_path = 'example_data/mim2gene.txt', output_txt=\"example_data/valid_mim_numbers.txt\", output_pkl=\"example_data/valid_mim_numbers.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting \"example_data/valid_mim_numbers.txt\" or \"example_data/valid_mim_numbers.pkl\" will contain the MIM numbers pertaining to all genes in the OMIM database. The rest of the process follows the instructions above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Disclaimer:** We note that, due to intellectual property restrictions outlined in the OMIM guidelines, we do not include the scraped knowledge base in our codebase. Instead, users can follow the above instructions to scrape and construct the OMIM database locally. Note that OMIM enforces a daily limit on the number of entries that can be queried. Scraping the entire database for RAG construction typically takes about 8 days with a single API key, or can be completed in one day using 8 API keys in parallel."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-lasso",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
