{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "135aef12",
   "metadata": {},
   "source": [
    "# LLM-Lasso Tutorial\n",
    "\n",
    "## 1. Setup Instructions\n",
    "1. Install `LLM-Lasso` as an editable package:\n",
    "    ```\n",
    "    $ pip install -e .\n",
    "    ```\n",
    "    for `pip`, or\n",
    "    ```\n",
    "    $ conda develop .\n",
    "    ```\n",
    "    for `conda`. Note that this requires you to `conda install conda-build`.\n",
    "\n",
    "2. Initialize the `adelie` submodule:\n",
    "    ```\n",
    "    $ git submodule init\n",
    "    $ git submodule update\n",
    "    ```\n",
    "3. Install `adelie` as an editable package (`adelie` is used for solving LASSO with penalty factors).\n",
    "    ```\n",
    "    $ cd adelie-fork\n",
    "    $ pip install -e .\n",
    "    ```\n",
    "    or the equivalent for `conda`.\n",
    "\n",
    "4. Copy the file `sample_constants.py` to `_my_constants.py` and populate relevant API keys.\n",
    "\n",
    "The values from `_my_constants.py` are automatically loaded into `constants.py`.\n",
    "\n",
    "### 1.1 Common issues:\n",
    "Intalling `adelie` as an editable package requires compiling from source, which may come with several issues:\n",
    "- `adelie` requires some C++ libraries, namely `eigen`, `llvm`, and `openmp` (which may be installed as `libomp`). For Unix-based systems, these should be available through your package manager, and releases are also available online.\n",
    "- There may issues with the `eigen` library (and others) not being in the `C_INCLUDE_PATH` and `CPLUS_INCLUDE_PATH`. For this, you need to:\n",
    "    - Find where the `eigen` include directory is on your machine (it should be a directory with subdirectories `Eigen` and `unsupported`). For macOS with `eigen` installed via `homebrew`, this may be in a directory that looks like `/opt/homebrew/Cellar/eigen/3.4.0_1/include/eigen3/`. For linux, this may be `/usr/include/eigen3/` or `/usr/local/include/eigen3/`, for instance.\n",
    "\n",
    "    - Run the following:\n",
    "        ```\n",
    "        $ export C_INCLUDE_PATH=\"the_path_from_the_previous_step:$C_INCLUDE_PATH\"\n",
    "        $ export CPLUS_INCLUDE_PATH=\"the_path_from_the_previous_step:$CPLUS_INCLUDE_PATH\"\n",
    "        ```\n",
    "    You may also have to do this with other libraries, like `libomp`.\n",
    "\n",
    "- If you installed `llvm` via `homebrew` on macOS, make sure you run the following:\n",
    "    ```\n",
    "    $ export LDFLAGS=\"-L/opt/homebrew/opt/llvm/lib\"\n",
    "    $ export CPPFLAGS=\"-I/opt/homebrew/opt/llvm/include\"\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a17c68d",
   "metadata": {},
   "source": [
    "## 2. Includes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636dfadf-b881-4cdf-856d-15fb48112c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_lasso.task_specific_lasso.llm_lasso import *\n",
    "from llm_lasso.task_specific_lasso.plotting import plot_heatmap, plot_llm_lasso_result\n",
    "from llm_lasso.data_splits import read_train_test_splits, read_baseline_splits\n",
    "import numpy as np\n",
    "import warnings\n",
    "import json\n",
    "warnings.filterwarnings(\"ignore\")  # Suppress warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a500bf4-1bbb-4ec9-9e3d-07d14efd3630",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985fe186-d9c6-4330-9d05-2110d2a8b452",
   "metadata": {},
   "source": [
    "## 3. Small-Scale Classification Example: Diabetes\n",
    "The first 4 steps will be run on the command line, and the remainder of the tutorial will be run using this notebook.\n",
    "### Step 1: Generate Training and Test Splits\n",
    "For evaluation, we consider 50/50 balanced training and test splits generated with different random seeds. As the same splits are used for the LASSO portion of LLM-Lasso and the data-driven baselines, we generate them beforehand.\n",
    "\n",
    "To generate $k$ train/test splits, run the following in the command line from the base directory of this repository:\n",
    "```\n",
    "$ python scripts/small_scale_splits.py \\\n",
    "        --dataset Diabetes \\\n",
    "        --save_dir data/splits/diabetes \\\n",
    "        --n-splits 10\n",
    "```\n",
    "\n",
    "**Corresponding shell script**: run `./shell_scripts/diabetes/step_01_splits.sh`\n",
    "\n",
    "\n",
    "### Step 2: Run Data-Driven Baselines\n",
    "Next, run the baseline feature-selected methods that require access to the training splits, e.g., mutual information.\n",
    "```\n",
    "$ python scripts/run_baselines.py \\\n",
    "        --split-dir data/splits/diabetes \\\n",
    "        --n-splits 10 \\\n",
    "        --save-dir data/baselines/diabetes\n",
    "```\n",
    "\n",
    "**Corresponding shell script**: run `./shell_scripts/diabetes/step_02_baselines.sh`\n",
    "\n",
    "\n",
    "### Step 3: Run the LLM-Score Baseline\n",
    "For example:\n",
    "```\n",
    "$ python scripts/llm_score.py \\\n",
    "        --prompt-filename prompts/llm-select/diabetes_prompt.txt \\\n",
    "        --feature_names_path small_scale/data/Diabetes_feature_names.pkl \\\n",
    "        --category Diabetes \\\n",
    "        --wipe \\\n",
    "        --save_dir data/llm-score/diabetes \\\n",
    "        --n-trials 1 \\\n",
    "        --step 1 \\\n",
    "        --model-type gpt-4o \\\n",
    "        --temp 0\n",
    "```\n",
    "\n",
    "**Corresponding shell script**: run `./shell_scripts/diabetes/step_03_llm_score_baseline.sh`\n",
    "\n",
    "\n",
    "### Step 4: Generate LLM-Lasso Penalties\n",
    "Note that there is no RAG setup for the small-scale datasets, so we will not enable RAG in the following script.\n",
    "```\n",
    "$ python scripts/llm_lasso_scores.py \\\n",
    "        --prompt-filename prompts/small_scale_prompts/diabetes_prompt.txt \\\n",
    "        --feature_names_path small_scale/data/Diabetes_feature_names.pkl \\\n",
    "        --category Diabetes \\\n",
    "        --wipe \\\n",
    "        --save_dir data/llm-lasso/diabetes \\\n",
    "        --n-trials 1 \\\n",
    "        --model-type gpt-4o \\\n",
    "        --temp 0\n",
    "```\n",
    "\n",
    "**Corresponding shell script**: run `./shell_scripts/diabetes/step_04_llm_lasso_penalties.sh`\n",
    "\n",
    "\n",
    "### Step 5: Run LLM-Regularized LASSO\n",
    "\n",
    "#### **Prepare Data**\n",
    "First, load in the required data splits, penalty factors, and baseline-selected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d032fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in splits\n",
    "N_SPLITS = 10\n",
    "splits = read_train_test_splits(\"../data/splits/diabetes\", N_SPLITS)\n",
    "n_features = splits[0].x_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39f0ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in LLM-Lasso Penalties\n",
    "penalty_list={\n",
    "    \"plain\": np.array(\n",
    "        np.load(\"../data/llm-lasso/diabetes/final_scores_plain.pkl\", allow_pickle=True)\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb233db-a02b-4aac-8221-ae8eec02dc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in baseline features\n",
    "feature_baseline = read_baseline_splits(\n",
    "    \"../data/baselines/diabetes\", n_splits=N_SPLITS, n_features=n_features)\n",
    "\n",
    "with open(\"../data/llm-score/diabetes/llmselect_selected_features.json\", \"r\") as f:\n",
    "    llm_select_genes = json.load(f)[f\"{n_features}\"]\n",
    "\n",
    "feature_baseline[\"llm_score\"] = [llm_select_genes] * N_SPLITS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768b66d5",
   "metadata": {},
   "source": [
    "#### **Run Experiments**\n",
    "\n",
    "LLM-Lasso experiments are set up in a **modular** fashion, so you run the baselines, Lasso, and LLM-Lasso separately.\n",
    "\n",
    "**Experiment Configuration:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26412baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = LLMLassoExperimentConfig(\n",
    "    folds_cv=5, # number of cross-validation folds\n",
    "    regression=False, # this is classification, not regression,\n",
    "    score_type=PenaltyType.PF, # We have penalty factors from the LLM,\n",
    "                               # not importance scores.\n",
    "    max_imp_power=4,\n",
    "    lambda_min_ratio=0.01, # Lasso parameter,\n",
    "    n_threads=8, # number of threads to use for computation\n",
    "    run_pure_lasso_after=5,\n",
    "    lasso_downstream_l2=True,\n",
    "    cross_val_metric=CrossValMetric.ERROR\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2066ba",
   "metadata": {},
   "source": [
    "**Run Data-Driven Baselines**\n",
    "\n",
    "This, along with all of the following experiment functions, outputs a Pandas `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009e9864",
   "metadata": {},
   "outputs": [],
   "source": [
    "baselines = run_downstream_baselines_for_splits(\n",
    "    splits=splits,\n",
    "    feature_baseline=feature_baseline,\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6985e6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e9d2a8",
   "metadata": {},
   "source": [
    "**Run Lasso Baseline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1c10d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = run_lasso_baseline_for_splits(\n",
    "    splits=splits,\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdf5fe1",
   "metadata": {},
   "source": [
    "**Run LLM-Lasso**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21646c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_lasso = run_llm_lasso_cv_for_splits(\n",
    "    splits=splits,\n",
    "    scores=penalty_list,\n",
    "    config=config,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab983029",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_lasso[llm_lasso[\"n_features\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15547cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso[lasso[\"n_features\"] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de27113",
   "metadata": {},
   "source": [
    "**Plotting Results**\n",
    "\n",
    "To plot the test error and AUROC, use `plot_llm_lasso_result` and pass in a list of all of the dataframes output by the previous experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9bb4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_to_plot = [df[df[\"n_features\"] > 0] for df in [lasso, baselines,llm_lasso]]\n",
    "plot_llm_lasso_result(\n",
    "    dataframes_to_plot,\n",
    "    bolded_methods=[\"1/imp - plain\"],\n",
    "    plot_error_bars=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c03189",
   "metadata": {},
   "source": [
    "You can also plot a feature inclusion heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c6d615",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(\n",
    "    [llm_lasso, lasso],\n",
    "    method_models=[\"1/imp - plain\", \"Lasso\"], # these are from the method_model column of the dataframe\n",
    "    labels=[\"LLM-Lasso\", \"Lasso\"], # this is how each method_model will be labeled on the plot\n",
    "    feature_names=splits[0].x_train.columns,\n",
    "    sort_by=\"LLM-Lasso\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1722ba4b",
   "metadata": {},
   "source": [
    "## 4. Small-Scale Regression Example: Spotify\n",
    "The first 4 steps will be run on the command line, and the remainder of the tutorial will be run using this notebook.\n",
    "### Command-Line Component\n",
    "Here are the commands to save data splits, run baselines, and generate penalties, same as for the Diabetes example:\n",
    "```\n",
    "$ python scripts/small_scale_splits.py \\\n",
    "        --dataset Spotify \\\n",
    "        --save_dir data/splits/spotify \\\n",
    "        --n-splits 10\n",
    "\n",
    "$ python scripts/run_baselines.py \\\n",
    "        --split-dir data/splits/spotify \\\n",
    "        --n-splits 10 \\\n",
    "        --save-dir data/baselines/spotify\n",
    "\n",
    "$ python scripts/llm_score.py \\\n",
    "        --prompt-filename prompts/llm-select/spotify_prompt.txt \\\n",
    "        --feature_names_path small_scale/data/Spotify_feature_names.pkl \\\n",
    "        --category \"number of Spotify streams\" \\\n",
    "        --wipe \\\n",
    "        --save_dir data/llm-score/spotify \\\n",
    "        --n-trials 1 \\\n",
    "        --step 1 \\\n",
    "        --model-type gpt-4o \\\n",
    "        --temp 0\n",
    "\n",
    "$ python scripts/llm_lasso_scores.py \\\n",
    "        --prompt-filename prompts/small_scale_prompts/spotify_prompt.txt \\\n",
    "        --feature_names_path small_scale/data/Spotify_feature_names.pkl \\\n",
    "        --category \"number of Spotify streams\" \\\n",
    "        --wipe \\\n",
    "        --save_dir data/llm-lasso/spotify \\\n",
    "        --n-trials 1 \\\n",
    "        --model-type gpt-4o \\\n",
    "        --temp 0\n",
    "```\n",
    "\n",
    "### LLM-Regularized LASSO\n",
    "First, load in the required data splits, penalty factors, and baseline-selected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05217011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in splits\n",
    "N_SPLITS = 10\n",
    "splits = read_train_test_splits(\"../data/splits/spotify\", N_SPLITS)\n",
    "n_features = splits[0].x_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a919914d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in LLM-Lasso Penalties\n",
    "penalty_list={\n",
    "    \"plain\": np.array(\n",
    "        np.load(\"../data/llm-lasso/spotify/final_scores_plain.pkl\", allow_pickle=True)\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d32c682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in baseline features\n",
    "feature_baseline = read_baseline_splits(\n",
    "    \"../data/baselines/spotify\", n_splits=N_SPLITS, n_features=n_features\n",
    ")\n",
    "\n",
    "with open(\"../data/llm-score/spotify/llmselect_selected_features.json\", \"r\") as f:\n",
    "    llm_select_genes = json.load(f)[f\"{n_features}\"]\n",
    "\n",
    "feature_baseline[\"llm_score\"] = [llm_select_genes] * N_SPLITS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5dc30f",
   "metadata": {},
   "source": [
    "Ccompute test error and AUROC for LLM-Lasso and the baselines, averaged across the splits.\n",
    "\n",
    "Make sure to pass in **`regression=True`** to `LLMLassoExperimentConfig`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774d3491",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = LLMLassoExperimentConfig(\n",
    "    folds_cv=10, # number of cross-validation folds\n",
    "    regression=True, # This is regression!!\n",
    "    score_type=PenaltyType.PF, # We have penalty factors from the LLM,\n",
    "                               # not importance scores.\n",
    "    lambda_min_ratio=0.001, # Lasso parameter,\n",
    "    n_threads=8, # number of threads to use for computation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65f1c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "baselines = run_downstream_baselines_for_splits(\n",
    "    splits=splits,\n",
    "    feature_baseline=feature_baseline,\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1557ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = run_lasso_baseline_for_splits(\n",
    "    splits=splits,\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7c1d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptive_lasso = run_adaptive_lasso_for_splits(\n",
    "    splits=splits,\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8c171a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost = run_xgboost_for_splits(\n",
    "    splits=splits,\n",
    "    ordered_features=feature_baseline[\"xgboost\"],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbce732",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_lasso = run_llm_lasso_cv_for_splits(\n",
    "    splits=splits,\n",
    "    scores=penalty_list,\n",
    "    config=config,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a105f727",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_llm_lasso_result(\n",
    "    [lasso, adaptive_lasso, baselines, xgboost, llm_lasso],\n",
    "    bolded_methods=[\"1/imp - plain\"],\n",
    "    plot_error_bars=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcce8fd9",
   "metadata": {},
   "source": [
    "Plot the feature inclusion heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f83b5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(\n",
    "    [lasso, llm_lasso],\n",
    "    method_models=[\"1/imp - plain\", \"Lasso\"], # these are from the method_model column of the dataframe\n",
    "    labels=[\"LLM-Lasso\", \"Lasso\"], # this is how each method_model will be labeled on the plot\n",
    "    feature_names=splits[0].x_train.columns,\n",
    "    sort_by=\"LLM-Lasso\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-lasso",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
