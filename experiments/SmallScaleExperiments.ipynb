{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM-Lasso: Small-Scale Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_lasso.task_specific_lasso.llm_lasso import *\n",
    "from llm_lasso.task_specific_lasso.plotting import plot_heatmap, plot_llm_lasso_result\n",
    "from llm_lasso.data_splits import read_train_test_splits, read_baseline_splits\n",
    "import numpy as np\n",
    "import warnings\n",
    "import json\n",
    "warnings.filterwarnings(\"ignore\")  # Suppress warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Diabetes\n",
    "### Step 1: Command-Line Portion\n",
    "\n",
    "Run the following in your command line\n",
    "```\n",
    "./shell_scripts/diabetes/step_01_splits.sh\n",
    "\n",
    "./shell_scripts/diabetes/step_02_baselines.sh\n",
    "\n",
    "./shell_scripts/diabetes/step_03_llm_score_baseline.sh\n",
    "\n",
    "./shell_scripts/diabetes/step_04_lmpriors_baseline.sh\n",
    "\n",
    "./shell_scripts/diabetes/step_05_llm_lasso_penalties.sh\n",
    "```\n",
    "\n",
    "### Step 2: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in splits\n",
    "N_SPLITS = 10\n",
    "splits = read_train_test_splits(\"../data/splits/diabetes\", N_SPLITS)\n",
    "n_features = splits[0].x_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in LLM-Lasso Penalties\n",
    "penalty_list={\n",
    "    \"plain\": np.array(\n",
    "        np.load(\"../data/llm-lasso/diabetes/final_scores_plain.pkl\", allow_pickle=True)\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in baseline features\n",
    "feature_baseline = read_baseline_splits(\n",
    "    \"../data/baselines/diabetes\", n_splits=N_SPLITS, n_features=n_features)\n",
    "\n",
    "with open(\"../data/lmpriors/diabetes/Diabetes/selected_features.txt\", \"r\") as f:\n",
    "    lmpriors = [line.strip() for line in f.readlines()]\n",
    "feature_baseline[\"lmpriors\"] = [lmpriors] * N_SPLITS\n",
    "\n",
    "with open(\"../data/llm-score/diabetes/llmselect_selected_features.json\", \"r\") as f:\n",
    "    llm_select_genes = json.load(f)[f\"{n_features}\"]\n",
    "\n",
    "feature_baseline[\"llm_score\"] = [llm_select_genes] * N_SPLITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = LLMLassoExperimentConfig(\n",
    "    folds_cv=5, # number of cross-validation folds\n",
    "    regression=False, # this is classification, not regression,\n",
    "    score_type=PenaltyType.PF, # We have penalty factors from the LLM,\n",
    "                               # not importance scores.\n",
    "    max_imp_power=4,\n",
    "    lambda_min_ratio=0.001, # Lasso parameter,\n",
    "    n_threads=8, # number of threads to use for computation\n",
    "    run_pure_lasso_after=5,\n",
    "    lasso_downstream_l2=True,\n",
    "    cross_val_metric=CrossValMetric.ERROR\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baselines = run_downstream_baselines_for_splits(\n",
    "    splits=splits,\n",
    "    feature_baseline=feature_baseline,\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = run_lasso_baseline_for_splits(\n",
    "    splits=splits,\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_lasso = run_llm_lasso_cv_for_splits(\n",
    "    splits=splits,\n",
    "    scores=penalty_list,\n",
    "    config=config,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_to_plot = [df[df[\"n_features\"] > 0] for df in [lasso, baselines,llm_lasso]]\n",
    "plot_llm_lasso_result(\n",
    "    dataframes_to_plot,\n",
    "    bolded_methods=[\"1/imp - plain\"],\n",
    "    plot_error_bars=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Bank\n",
    "### Step 1: Command-Line Portion\n",
    "\n",
    "Run the following in your command line\n",
    "```\n",
    "./shell_scripts/bank/step_01_splits.sh\n",
    "\n",
    "./shell_scripts/bank/step_02_baselines.sh\n",
    "\n",
    "./shell_scripts/bank/step_03_llm_score_baseline.sh\n",
    "\n",
    "./shell_scripts/bank/step_04_lmpriors_baseline.sh\n",
    "\n",
    "./shell_scripts/bank/step_05_llm_lasso_penalties.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in splits\n",
    "N_SPLITS = 10\n",
    "splits = read_train_test_splits(\"../data/splits/bank\", N_SPLITS)\n",
    "n_features = splits[0].x_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in LLM-Lasso Penalties\n",
    "penalty_list={\n",
    "    \"plain\": np.array(\n",
    "        np.load(\"../data/llm-lasso/bank/final_scores_plain.pkl\", allow_pickle=True)\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in baseline features\n",
    "feature_baseline = read_baseline_splits(\n",
    "    \"../data/baselines/bank\", n_splits=N_SPLITS, n_features=n_features)\n",
    "\n",
    "with open(\"../data/llm-score/bank/llmselect_selected_features.json\", \"r\") as f:\n",
    "    llm_select_genes = json.load(f)[f\"{n_features}\"]\n",
    "\n",
    "with open(\"../data/lmpriors/bank/Bank/selected_features.txt\", \"r\") as f:\n",
    "    lmpriors = [line.strip() for line in f.readlines()]\n",
    "feature_baseline[\"lmpriors\"] = [lmpriors] * N_SPLITS\n",
    "\n",
    "feature_baseline[\"llm_score\"] = [llm_select_genes] * N_SPLITS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For Bank, we have to remove the `duration` feature, which, according to the dataset description \"should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_idx = splits[0].x_train.columns.tolist().index(\"duration\")\n",
    "for i in range(N_SPLITS):\n",
    "    splits[i].x_train = splits[i].x_train.drop(\"duration\", axis=1)\n",
    "    splits[i].x_test = splits[i].x_test.drop(\"duration\", axis=1)\n",
    "\n",
    "    for key in feature_baseline:\n",
    "        if \"duration\" in feature_baseline[key][i]:\n",
    "            feature_baseline[key][i].remove(\"duration\")\n",
    "\n",
    "plain = penalty_list[\"plain\"].tolist()\n",
    "penalty_list[\"plain\"] = np.array(\n",
    "    plain[:duration_idx] + plain[duration_idx+1:]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = LLMLassoExperimentConfig(\n",
    "    folds_cv=5, # number of cross-validation folds\n",
    "    regression=False, # this is classification, not regression,\n",
    "    score_type=PenaltyType.PF, # We have penalty factors from the LLM,\n",
    "                               # not importance scores.\n",
    "    max_imp_power=2,\n",
    "    lambda_min_ratio=0.001, # Lasso parameter,\n",
    "    n_threads=8, # number of threads to use for computation\n",
    "    run_pure_lasso_after=5,\n",
    "    lasso_downstream_l2=True,\n",
    "    cross_val_metric=CrossValMetric.AUROC\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baselines = run_downstream_baselines_for_splits(\n",
    "    splits=splits,\n",
    "    feature_baseline=feature_baseline,\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = run_lasso_baseline_for_splits(\n",
    "    splits=splits,\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_lasso = run_llm_lasso_cv_for_splits(\n",
    "    splits=splits,\n",
    "    scores=penalty_list,\n",
    "    config=config,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_to_plot = [df[df[\"n_features\"] > 0] for df in [lasso, baselines,llm_lasso]]\n",
    "plot_llm_lasso_result(\n",
    "    dataframes_to_plot,\n",
    "    bolded_methods=[\"1/imp - plain\"],\n",
    "    plot_error_bars=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Spotify\n",
    "### Step 1: Command-Line Portion\n",
    "\n",
    "Run the following in your command line\n",
    "```\n",
    "./shell_scripts/spotify/step_01_splits.sh\n",
    "\n",
    "./shell_scripts/spotify/step_02_baselines.sh\n",
    "\n",
    "./shell_scripts/spotify/step_03_llm_score_baseline.sh\n",
    "\n",
    "./shell_scripts/spotify/step_04_lmpriors_baseline.sh\n",
    "\n",
    "./shell_scripts/spotify/step_05_llm_lasso_penalties.sh\n",
    "```\n",
    "\n",
    "### Step 2: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in splits\n",
    "N_SPLITS = 10\n",
    "splits = read_train_test_splits(\"../data/splits/spotify\", N_SPLITS)\n",
    "n_features = splits[0].x_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in LLM-Lasso Penalties\n",
    "penalty_list={\n",
    "    \"plain\": np.array(\n",
    "        np.load(\"../data/llm-lasso/spotify/final_scores_plain.pkl\", allow_pickle=True)\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in baseline features\n",
    "feature_baseline = read_baseline_splits(\n",
    "    \"../data/baselines/spotify\", n_splits=N_SPLITS, n_features=n_features)\n",
    "\n",
    "with open(\"../data/llm-score/spotify/llmselect_selected_features.json\", \"r\") as f:\n",
    "    llm_select_genes = json.load(f)[f\"{n_features}\"]\n",
    "\n",
    "with open(\"../data/lmpriors/spotify/Spotify/selected_features.txt\", \"r\") as f:\n",
    "    lmpriors = [line.strip() for line in f.readlines()]\n",
    "feature_baseline[\"lmpriors\"] = [lmpriors] * N_SPLITS\n",
    "\n",
    "feature_baseline[\"llm_score\"] = [llm_select_genes] * N_SPLITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = LLMLassoExperimentConfig(\n",
    "    folds_cv=5, # number of cross-validation folds\n",
    "    regression=True, # this is regression\n",
    "    score_type=PenaltyType.PF, # We have penalty factors from the LLM,\n",
    "                               # not importance scores.\n",
    "    max_imp_power=4,\n",
    "    lambda_min_ratio=0.001, # Lasso parameter,\n",
    "    n_threads=8, # number of threads to use for computation\n",
    "    run_pure_lasso_after=5,\n",
    "    lasso_downstream_l2=True,\n",
    "    cross_val_metric=CrossValMetric.ERROR\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baselines = run_downstream_baselines_for_splits(\n",
    "    splits=splits,\n",
    "    feature_baseline=feature_baseline,\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = run_lasso_baseline_for_splits(\n",
    "    splits=splits,\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_lasso = run_llm_lasso_cv_for_splits(\n",
    "    splits=splits,\n",
    "    scores=penalty_list,\n",
    "    config=config,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_to_plot = [df[df[\"n_features\"] > 0] for df in [lasso, baselines,llm_lasso]]\n",
    "plot_llm_lasso_result(\n",
    "    dataframes_to_plot,\n",
    "    bolded_methods=[\"1/imp - plain\"],\n",
    "    plot_error_bars=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Wine\n",
    "### Step 1: Command-Line Portion\n",
    "\n",
    "Run the following in your command line\n",
    "```\n",
    "./shell_scripts/wine/step_01_splits.sh\n",
    "\n",
    "./shell_scripts/wine/step_02_baselines.sh\n",
    "\n",
    "./shell_scripts/wine/step_03_llm_score_baseline.sh\n",
    "\n",
    "./shell_scripts/wine/step_04_lmpriors_baseline.sh\n",
    "\n",
    "./shell_scripts/wine/step_05_llm_lasso_penalties.sh\n",
    "```\n",
    "\n",
    "### Step 2: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in splits\n",
    "N_SPLITS = 10\n",
    "splits = read_train_test_splits(\"../data/splits/wine\", N_SPLITS)\n",
    "n_features = splits[0].x_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in LLM-Lasso Penalties\n",
    "penalty_list={\n",
    "    \"plain\": np.array(\n",
    "        np.load(\"../data/llm-lasso/wine/final_scores_plain.pkl\", allow_pickle=True)\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in baseline features\n",
    "feature_baseline = read_baseline_splits(\n",
    "    \"../data/baselines/wine\", n_splits=N_SPLITS, n_features=n_features)\n",
    "\n",
    "with open(\"../data/llm-score/wine/llmselect_selected_features.json\", \"r\") as f:\n",
    "    llm_select_genes = json.load(f)[f\"{n_features}\"]\n",
    "\n",
    "with open(\"../data/lmpriors/wine/Wine/selected_features.txt\", \"r\") as f:\n",
    "    lmpriors = [line.strip() for line in f.readlines()]\n",
    "    lmpriors = [x[0].lower() + x[1:] for x in lmpriors]\n",
    "feature_baseline[\"lmpriors\"] = [lmpriors] * N_SPLITS\n",
    "\n",
    "feature_baseline[\"llm_score\"] = [llm_select_genes] * N_SPLITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = LLMLassoExperimentConfig(\n",
    "    folds_cv=5, # number of cross-validation folds\n",
    "    regression=True, # this is regression\n",
    "    score_type=PenaltyType.PF, # We have penalty factors from the LLM,\n",
    "                               # not importance scores.\n",
    "    max_imp_power=2,\n",
    "    lambda_min_ratio=0.001, # Lasso parameter,\n",
    "    n_threads=8, # number of threads to use for computation\n",
    "    run_pure_lasso_after=5,\n",
    "    lasso_downstream_l2=True,\n",
    "    cross_val_metric=CrossValMetric.ERROR\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baselines = run_downstream_baselines_for_splits(\n",
    "    splits=splits,\n",
    "    feature_baseline=feature_baseline,\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = run_lasso_baseline_for_splits(\n",
    "    splits=splits,\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_lasso = run_llm_lasso_cv_for_splits(\n",
    "    splits=splits,\n",
    "    scores=penalty_list,\n",
    "    config=config,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_to_plot = [df[df[\"n_features\"] > 0] for df in [lasso, baselines,llm_lasso]]\n",
    "plot_llm_lasso_result(\n",
    "    dataframes_to_plot,\n",
    "    bolded_methods=[\"1/imp - plain\"],\n",
    "    plot_error_bars=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Glioma\n",
    "### Step 1: Command-Line Portion\n",
    "\n",
    "Run the following in your command line\n",
    "```\n",
    "./shell_scripts/glioma/step_01_splits.sh\n",
    "\n",
    "./shell_scripts/glioma/step_02_baselines.sh\n",
    "\n",
    "./shell_scripts/glioma/step_03_llm_score_baseline.sh\n",
    "\n",
    "./shell_scripts/glioma/step_04_lmpriors_baseline.sh\n",
    "\n",
    "./shell_scripts/glioma/step_05_llm_lasso_penalties.sh\n",
    "```\n",
    "\n",
    "### Step 2: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in splits\n",
    "N_SPLITS = 10\n",
    "splits = read_train_test_splits(\"../data/splits/glioma\", N_SPLITS)\n",
    "n_features = splits[0].x_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in LLM-Lasso Penalties\n",
    "penalty_list={\n",
    "    \"plain\": np.array(\n",
    "        np.load(\"../data/llm-lasso/glioma/final_scores_plain.pkl\", allow_pickle=True)\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in baseline features\n",
    "feature_baseline = read_baseline_splits(\n",
    "    \"../data/baselines/glioma\", n_splits=N_SPLITS, n_features=n_features)\n",
    "\n",
    "with open(\"../data/llm-score/glioma/llmselect_selected_features.json\", \"r\") as f:\n",
    "    llm_select_genes = json.load(f)[f\"{n_features}\"]\n",
    "\n",
    "with open(\"../data/lmpriors/glioma/Glioma/selected_features.txt\", \"r\") as f:\n",
    "    lmpriors = [line.strip() for line in f.readlines()]\n",
    "feature_baseline[\"lmpriors\"] = [lmpriors] * N_SPLITS\n",
    "\n",
    "feature_baseline[\"llm_score\"] = [llm_select_genes] * N_SPLITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = LLMLassoExperimentConfig(\n",
    "    folds_cv=5, # number of cross-validation folds\n",
    "    regression=False, # this is not regression\n",
    "    score_type=PenaltyType.PF, # We have penalty factors from the LLM,\n",
    "                               # not importance scores.\n",
    "    max_imp_power=2,\n",
    "    lambda_min_ratio=0.001, # Lasso parameter,\n",
    "    n_threads=8, # number of threads to use for computation\n",
    "    run_pure_lasso_after=5,\n",
    "    lasso_downstream_l2=True,\n",
    "    cross_val_metric=CrossValMetric.ERROR\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baselines = run_downstream_baselines_for_splits(\n",
    "    splits=splits,\n",
    "    feature_baseline=feature_baseline,\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = run_lasso_baseline_for_splits(\n",
    "    splits=splits,\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_lasso = run_llm_lasso_cv_for_splits(\n",
    "    splits=splits,\n",
    "    scores=penalty_list,\n",
    "    config=config,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_to_plot = [df[df[\"n_features\"] > 0] for df in [lasso, baselines,llm_lasso]]\n",
    "plot_llm_lasso_result(\n",
    "    dataframes_to_plot,\n",
    "    bolded_methods=[\"1/imp - plain\"],\n",
    "    plot_error_bars=False,\n",
    "    test_error_y_lim=(0.13, 0.2),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-lasso",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
