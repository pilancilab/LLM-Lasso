{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM-Lasso: Spotify Model Ablations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_lasso.data_splits import read_train_test_splits, read_baseline_splits\n",
    "from llm_lasso.task_specific_lasso.llm_lasso import *\n",
    "from llm_lasso.task_specific_lasso.plotting import plot_llm_lasso_result, plot_heatmap, \\\n",
    "    LLM_LASSO_COLORS, BASELINE_COLORS, LASSO_COLOR\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Command-Line Portion\n",
    "\n",
    "Run the following in your command line\n",
    "```\n",
    "./shell_scripts/spotify/step_01_splits.sh\n",
    "\n",
    "./shell_scripts/model_ablation_spotify/gpt_4o.sh\n",
    "\n",
    "./shell_scripts/model_ablation_spotify/o1.sh\n",
    "\n",
    "./shell_scripts/model_ablation_spotify/deepseek.sh\n",
    "\n",
    "./shell_scripts/model_ablation_spotify/gpt3_5.sh\n",
    "\n",
    "./shell_scripts/model_ablation_spotify/llama8b.sh\n",
    "\n",
    "./shell_scripts/model_ablation_spotify/llama405b.sh\n",
    "```\n",
    "\n",
    "**Note**: Between when the results presented in the LLM-Lasso paper were collected and our submission, `qwen/qvq-72b-preview` stopped being openly available on `openrouter` (you need to request access now). So, this notebook does not include `qwen` results.\n",
    "\n",
    "### Step 2: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SPLITS = 10\n",
    "DATASET=\"spotify\"\n",
    "BASE_FOLDER=\"../data/experiment-results\"\n",
    "os.makedirs(f\"{BASE_FOLDER}/{DATASET}\", exist_ok=True)\n",
    "splits = read_train_test_splits(f\"../data/splits/{DATASET}\", N_SPLITS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = LLMLassoExperimentConfig(\n",
    "    folds_cv=5,\n",
    "    regression=True,\n",
    "    max_features_for_baselines=30,\n",
    "    n_threads=8,\n",
    "\n",
    "    # Lasso config\n",
    "    lambda_min_ratio=0.001,\n",
    "    relaxed_lasso=False,\n",
    "    lasso_downstream_l2=True,\n",
    "    max_imp_power=2,\n",
    "\n",
    "    run_pure_lasso_after=2,\n",
    "    cross_val_metric=CrossValMetric.ERROR\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RERUN_LASSO = True\n",
    "EXPERIMENT_NAME = \"logistic\"\n",
    "\n",
    "lasso_csv = f\"{BASE_FOLDER}/{DATASET}/lasso_{EXPERIMENT_NAME}.csv\"\n",
    "\n",
    "if not RERUN_LASSO and os.path.exists(lasso_csv):\n",
    "    print(f\"CSV found at {lasso_csv}. Loading.\")\n",
    "    lasso = pd.read_csv(lasso_csv)\n",
    "else:\n",
    "    lasso = run_lasso_baseline_for_splits(\n",
    "        splits=splits,\n",
    "        config=config\n",
    "    )\n",
    "    lasso.to_csv(lasso_csv, index=False)\n",
    "lasso[\"llm\"] = \"Lasso\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    \"gpt-3.5-turbo-0613\",\n",
    "    \"gpt-4o\",\n",
    "    \"o1\",\n",
    "    \"llama-3-8b-instruct\",\n",
    "    \"llama-3.1-405b-instruct\",\n",
    "    \"deepseek\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_plain = [lasso]\n",
    "\n",
    "RERUN_LLM_LASSO = True\n",
    "\n",
    "for model in models:\n",
    "    print(model)\n",
    "    with open(f\"../data/llm-lasso/spotify/{model}/final_scores_plain.txt\") as f:\n",
    "        plain_scores = np.array([float(x) for x in f.readlines()])\n",
    "    llm_lasso_csv = f\"{BASE_FOLDER}/{DATASET}/llm_lasso_{model}.csv\"\n",
    "\n",
    "    if not RERUN_LLM_LASSO and os.path.exists(llm_lasso_csv):\n",
    "        print(f\"CSV found at {llm_lasso_csv}. Loading.\")\n",
    "        llm_lasso = pd.read_csv(llm_lasso_csv)\n",
    "    else:\n",
    "        llm_lasso = run_llm_lasso_cv_for_splits(\n",
    "            splits=splits,\n",
    "            scores={\n",
    "                \"plain\": plain_scores,\n",
    "            },\n",
    "            config=config,\n",
    "            verbose=False,\n",
    "        )\n",
    "        llm_lasso.to_csv(llm_lasso_csv, index=False)\n",
    "    llm_lasso[\"llm\"] = model\n",
    "    dataframes_plain.append(llm_lasso[llm_lasso[\"method_model\"] == \"1/imp - plain\"])\n",
    "\n",
    "all_results_plain = pd.concat(dataframes_plain, ignore_index=True).copy()\n",
    "all_results_plain = all_results_plain[all_results_plain[\"n_features\"] == 5][[\"test_error\", \"auroc\", \"llm\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = (\n",
    "    all_results_plain\n",
    "    .groupby('llm', dropna=False)\n",
    "    .agg(\n",
    "        mean=('test_error', 'mean'),\n",
    "        qlow=('test_error', lambda x: x.quantile(0.05)),\n",
    "        qhigh=('test_error', lambda x: x.quantile(0.95)),\n",
    "    ).reset_index()\n",
    ")\n",
    "argsort = summary.sort_values(by=\"mean\").index.tolist()\n",
    "colors =  [\"#aaaaaa\"] + LLM_LASSO_COLORS + BASELINE_COLORS\n",
    "colors = [colors[i] for i in argsort]\n",
    "summary = summary.sort_values(by=\"mean\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = np.zeros((2, summary.shape[0]))\n",
    "errors[0, :] = summary[\"mean\"] - summary[\"qlow\"]\n",
    "errors[1, :] = summary[\"qhigh\"] - summary[\"mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.grid(zorder=0)\n",
    "barplot = sns.barplot(\n",
    "    data=summary,\n",
    "    x='llm',\n",
    "    y='mean',\n",
    "    hue=\"llm\",\n",
    "    palette=colors,\n",
    "    alpha=0.8,\n",
    "    edgecolor=\"black\",\n",
    "    errorbar=None,\n",
    "    zorder=3\n",
    ")\n",
    "\n",
    "# Add error bars manually\n",
    "plt.errorbar(\n",
    "    x=range(len(summary)),\n",
    "    y=summary['mean'],\n",
    "    yerr=errors,\n",
    "    fmt='none',\n",
    "    c='black',\n",
    "    capsize=5,\n",
    "    zorder=5\n",
    ")\n",
    "\n",
    "# Customize\n",
    "plt.title('Plain LLM-Lasso Test Error: Spotify (Model Ablation)', fontdict={\"size\": 21})\n",
    "plt.xlabel(None)\n",
    "plt.ylabel('Test Error', fontdict={\"size\": 18})\n",
    "plt.xticks([])\n",
    "plt.tick_params(axis='both', labelsize=14) \n",
    "\n",
    "labels = summary['llm'].tolist()\n",
    "plt.legend(labels=labels, bbox_to_anchor=(1.05, 1), loc='upper left',\n",
    "           fontsize=16)\n",
    "# plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-lasso",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
