{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mllm_lasso\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_splits\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m read_train_test_splits, read_baseline_splits\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mllm_lasso\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtask_specific_lasso\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllm_lasso\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mllm_lasso\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtask_specific_lasso\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplotting\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m plot_llm_lasso_result, plot_heatmap\n",
      "File \u001b[0;32m~/PycharmProjects/pilancilab-llm-lasso/src/llm_lasso/data_splits.py:5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mllm_lasso\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtask_specific_lasso\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TrainTest\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Helper function to create balanced folds\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbalanced_folds\u001b[39m(data_labels, nfolds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "File \u001b[0;32m~/PycharmProjects/pilancilab-llm-lasso/src/llm_lasso/task_specific_lasso/utils.py:12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01madelie\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdiagnostic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m auc_roc, test_error_hamming, test_error_mse, predict\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterpolate\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m interp1d\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mxgboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mxgb\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mregex\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdataclasses\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dataclass\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "from llm_lasso.data_splits import read_train_test_splits, read_baseline_splits\n",
    "from llm_lasso.task_specific_lasso.llm_lasso import *\n",
    "from llm_lasso.task_specific_lasso.plotting import plot_llm_lasso_result, plot_heatmap\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentation on ETP Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m DATASET\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mETP\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m BASE_FOLDER\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/experiment-results\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mBASE_FOLDER\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDATASET\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m splits \u001b[38;5;241m=\u001b[39m read_train_test_splits(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/splits/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDATASET\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, N_SPLITS)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "N_SPLITS = 10\n",
    "DATASET=\"ETP\"\n",
    "BASE_FOLDER=\"data/experiment-results\"\n",
    "os.makedirs(f\"{BASE_FOLDER}/{DATASET}\", exist_ok=True)\n",
    "splits = read_train_test_splits(f\"data/splits/{DATASET}\", N_SPLITS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_baseline = read_baseline_splits(f\"data/baselines/{DATASET}\", n_splits=N_SPLITS, n_features=49)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Experiment Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = LLMLassoExperimentConfig(\n",
    "    folds_cv=5,\n",
    "    regression=False,\n",
    "    max_features_for_baselines=30,\n",
    "    n_threads=8,\n",
    "\n",
    "    # Lasso config\n",
    "    lambda_min_ratio=0.001,\n",
    "    relaxed_lasso=False,\n",
    "    lasso_downstream_l2=True,\n",
    "    max_imp_power=4,\n",
    "\n",
    "    remove_correlated_features=False,\n",
    "    run_pure_lasso_after=8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Run Baselines\n",
    "\n",
    "All experiments (baselines, Lasso, LLM-Lasso, etc.) in this notebook have the same structure:\n",
    "1. **Step 1**: Look for previous results in the specified CSV file (for the baselines, it's `data/experiment-results/ETP/baselines.csv`, as defined in the variable `baseline_csv` below).\n",
    "    If the CSV is found, and the variable **`RERUN_BASELINES`** (e.g.) is not set `True`, then we just load in the CSV.\n",
    "2. **Step 2**: if the CSV is not found, run the experiment, e.g., `run_all_baselines_for_splits`.\n",
    "3. **Step 3**: save the experiments to CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RERUN_BASELINES = False\n",
    "\n",
    "baseline_csv = f\"{BASE_FOLDER}/{DATASET}/baselines.csv\"\n",
    "if not RERUN_BASELINES and os.path.exists(baseline_csv):\n",
    "    print(f\"CSV found at {baseline_csv}. Loading.\")\n",
    "    baselines = pd.read_csv(baseline_csv)\n",
    "else:\n",
    "    baselines = run_all_baselines_for_splits(\n",
    "        splits=splits,\n",
    "        feature_baseline=feature_baseline,\n",
    "        config=config\n",
    "    )\n",
    "    baselines.to_csv(baseline_csv, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: for Lasso, LLM-Lasso, and Adaptive Lasso, this notebook defines an **`EXPERIMENT_NAME`** variable, which is added to the CSV filename to allow for saving multiple CSVs in the same directory with different experiment configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RERUN_LASSO = False\n",
    "EXPERIMENT_NAME = \"logistic\"\n",
    "\n",
    "lasso_csv = f\"{BASE_FOLDER}/{DATASET}/lasso_{EXPERIMENT_NAME}.csv\"\n",
    "\n",
    "if not RERUN_LASSO and os.path.exists(lasso_csv):\n",
    "    print(f\"CSV found at {lasso_csv}. Loading.\")\n",
    "    lasso = pd.read_csv(lasso_csv)\n",
    "else:\n",
    "    lasso = run_lasso_baseline_for_splits(\n",
    "        splits=splits,\n",
    "        config=config\n",
    "    )\n",
    "    lasso.to_csv(lasso_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RERUN_ADAPTIVE_LASSO = True\n",
    "EXPERIMENT_NAME = \"logistic\"\n",
    "\n",
    "adaptive_lasso_csv = f\"{BASE_FOLDER}/{DATASET}/adaptive_lasso_{EXPERIMENT_NAME}.csv\"\n",
    "\n",
    "if not RERUN_ADAPTIVE_LASSO and os.path.exists(adaptive_lasso_csv):\n",
    "    print(f\"CSV found at {adaptive_lasso_csv}. Loading.\")\n",
    "    adaptive_lasso = pd.read_csv(adaptive_lasso_csv)\n",
    "else:\n",
    "    adaptive_lasso = run_adaptive_lasso_for_splits(\n",
    "        splits=splits,\n",
    "        config=config\n",
    "    )\n",
    "    adaptive_lasso.to_csv(adaptive_lasso_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RERUN_XGBOOST = False\n",
    "\n",
    "xgboost_csv = f\"{BASE_FOLDER}/{DATASET}/xgboost.csv\"\n",
    "\n",
    "if not RERUN_XGBOOST and os.path.exists(xgboost_csv):\n",
    "    print(f\"CSV found at {xgboost_csv}. Loading.\")\n",
    "    xgboost = pd.read_csv(xgboost_csv)\n",
    "else:\n",
    "    xgboost = run_xgboost_for_splits(\n",
    "        splits=splits,\n",
    "        ordered_features=feature_baseline[\"xgboost\"],\n",
    "        config=config\n",
    "    )\n",
    "    xgboost.to_csv(xgboost_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate using the web interface on the subset provided by XGBoost\n",
    "manually_tuned_penalties = {\n",
    "  \"AEBP1\": 0.8,\n",
    "  \"ANP32B\": 0.8,\n",
    "  \"CCND2\": 0.2,\n",
    "  \"CD164\": 0.8,\n",
    "  \"CD1B\": 0.2,\n",
    "  \"CD5\": 0.2,\n",
    "  \"DEFA1\": 0.8,\n",
    "  \"DEK\": 0.8,\n",
    "  \"DNAJC1\": 0.8,\n",
    "  \"EGR1\": 0.2,\n",
    "  \"ELOVL4\": 0.8,\n",
    "  \"EPHB6\": 0.8,\n",
    "  \"GALNT2\": 0.8,\n",
    "  \"GPX4\": 0.8,\n",
    "  \"HIST1H2AD\": 0.8,\n",
    "  \"IGFBP7\": 0.8,\n",
    "  \"IL7R\": 0.8,\n",
    "  \"ILF3\": 0.8,\n",
    "  \"JARID2\": 0.8,\n",
    "  \"JUN\": 0.8,\n",
    "  \"KLF10\": 0.8,\n",
    "  \"KLHDC3\": 0.8,\n",
    "  \"KMT2E\": 0.8,\n",
    "  \"LAT2\": 0.7,\n",
    "  \"LEF1\": 0.2,\n",
    "}\n",
    "\n",
    "\n",
    "penalties = []\n",
    "for gene in splits[0].x_test.columns:\n",
    "    penalties.append(1 if gene not in manually_tuned_penalties else manually_tuned_penalties[gene])\n",
    "penalties = np.array(penalties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/llm-lasso/etp_manual.json\", \"r\") as f:\n",
    "    json_penalties = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penalties_per_split = []\n",
    "for spl in json_penalties:\n",
    "    penalties = []\n",
    "    for gene in splits[0].x_test.columns:\n",
    "        penalties.append(1 if gene not in spl else spl[gene])\n",
    "    # penalties = np.array(penalties)\n",
    "    penalties_per_split.append(penalties)\n",
    "penalties_per_split = np.array(penalties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# penalties = np.array(np.load(\"data/llm-lasso/ETP/final_scores_RAG.pkl\", allow_pickle=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RERUN_LLM_LASSO = True\n",
    "EXPERIMENT_NAME = \"chatgpt\"\n",
    "\n",
    "llm_lasso_csv = f\"{BASE_FOLDER}/{DATASET}/llm_lasso_{EXPERIMENT_NAME}.csv\"\n",
    "\n",
    "if not RERUN_LLM_LASSO and os.path.exists(llm_lasso_csv):\n",
    "    print(f\"CSV found at {llm_lasso_csv}. Loading.\")\n",
    "    llm_lasso = pd.read_csv(llm_lasso_csv)\n",
    "else:\n",
    "    llm_lasso = run_llm_lasso_cv_for_splits(\n",
    "        splits=splits,\n",
    "        scores={\"chatGPT\": penalties_per_split},\n",
    "        config=config,\n",
    "        verbose=True\n",
    "    )\n",
    "    llm_lasso.to_csv(llm_lasso_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This line means that we only plot a few of the (better-performing) baselines!\n",
    "filtered_baselines = baselines[baselines[\"method\"].isin([\"xgboost\", \"XGBoost_Model\", \"mrmr\"])]\n",
    "\n",
    "dataframes_to_plot = [\n",
    "    filtered_baselines, lasso, xgboost, llm_lasso, adaptive_lasso\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_llm_lasso_result(\n",
    "    dataframes_to_plot,\n",
    "    bolded_methods=[\"1/imp - chatGPT\"],\n",
    "    plot_error_bars=False,\n",
    "    x_lim=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(\n",
    "    dataframes_to_plot,\n",
    "    method_models=[\"1/imp - chatGPT\", \"xgboost\", \"Lasso\"], # these are from the method_model column of the dataframe\n",
    "    labels=[\"LLM-Lasso\", \"XGBoost\", \"Lasso\"], # this is how each method_model will be labeled on the plot\n",
    "    feature_names=splits[0].x_train.columns,\n",
    "    sort_by=\"LLM-Lasso\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The below is some experimentation with prompt tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_lasso.llm_penalty.llm import LLMQueryWrapperWithMemory, LLMType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "In using gene expression levels for classifying ETP-All vs. non-ETP-All, assign each of these genes a score between 0.1 and 0.9, where 0.1 means very important and 0.9 means less important. It's ok to assign many genes 0.9 if they aren't super important. It's normal for only a few genes to be important.\n",
    "\n",
    "Think carefully for each gene. Format your response as a JSON.\n",
    "\n",
    "\"\"\" + str(sorted(feature_baseline[\"xgboost\"][9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import constants\n",
    "os.environ[\"OPENAI_API_KEY\"] = constants.OPENAI_API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = LLMQueryWrapperWithMemory(\n",
    "    llm_type=LLMType.O1,\n",
    "    llm_name=\"o1\",\n",
    "    api_key=constants.OPENAI_API\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_json = llm.query(\n",
    "    system_message=\"\",\n",
    "    full_prompt=prompt,\n",
    "    sleep_time=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-lasso",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
