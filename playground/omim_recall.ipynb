{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "import constants\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = constants.OPENAI_API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_QUERIES = [\n",
    "    \"Retrieve information about gene AICDA, DLBCL (diffuse large B-cell lymphoma) and FL (follicular lymphoma), especially in the context of AICDA's relevance to DLBCL and FL.\",\n",
    "    \"Retrieve information about gene BCL6, DLBCL (diffuse large B-cell lymphoma) and MCL (mantle cell lymphoma), especially in the context of BCL6's relevance to DLBCL and MCL.\",\n",
    "    \"Retrieve information about gene AASS, cHL (Classical Hodgkin Lymphoma) and MCL (mantle cell lymphoma), especially in the context of AASS's relevance to MCL and cHL.\"\n",
    "]\n",
    "DEVICE=\"cuda:7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = Chroma(persist_directory=\"../\" + constants.OMIM_PERSIST_DIRECTORY, embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embeds = torch.Tensor(embeddings.embed_documents(TEST_QUERIES)).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_docs = vectorstore._collection.get(include=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ids = all_docs[\"ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = []\n",
    "for j in range(test_embeds.shape[0]):\n",
    "    test = test_embeds[j, :]\n",
    "    cosine = torch.zeros(len(all_ids), device=DEVICE)\n",
    "    for i in tqdm(range(0, len(all_ids), BATCH_SIZE)):\n",
    "        ids = all_ids[i:i+BATCH_SIZE]\n",
    "        embed = torch.from_numpy(vectorstore._collection.get(ids, include=[\"embeddings\"])[\"embeddings\"]).to(DEVICE)\n",
    "\n",
    "        cosine[i:i+BATCH_SIZE] = torch.sum(test * embed, dim=1) / (torch.sum(embed.square(), dim=1).sqrt() * torch.norm(test))\n",
    "    argsort = torch.argsort(cosine, descending=True)\n",
    "    ground_truth.append([all_ids[i] for i in argsort])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queried = vectorstore._collection.query(query_texts=TEST_QUERIES, query_embeddings=test_embeds.tolist(), n_results=K)[\"ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recalls = []\n",
    "for j in range(len(TEST_QUERIES)):\n",
    "    recalls.append(len(set(ground_truth[j][:K]).intersection(set(queried[j]))) / K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(recalls) / len(recalls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-lasso",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
